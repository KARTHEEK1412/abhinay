# -*- coding: utf-8 -*-
"""nip1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YvKvN8vOBS-iDO8iOpI5SK1D-vdUcfQx
"""

import pandas as pd

a=['congrats. you have won a lottery ticket and you can get the lottery amount by callin on this lottery number',
   'Give your bank details for lottery',
   'lottert for sure if bank details verified']

type(a)

# tokeization
a[0].split()

a[1].split()

a[2].split()

#count Vectorization-feature exraction technique
from sklearn.feature_extraction.text import CountVectorizer

b=CountVectorizer(stop_words='english') #exclude all the stop words and gives rest of the words
b

op=b.fit_transform(a).toarray()
op

df=pd.DataFrame(op,columns=b.get_feature_names())
df

df=pd.read_table('https://raw.githubusercontent.com/arib168/data/main/spam.tsv')

df

df.message[2]

df.message[1500]

df.label[1500]

df.info()

df.label.value_counts()

x=df.message.values
y=df.label.values

x

y

#train test split
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0)

x.shape

x_train.shape

x_test.shape

vect=CountVectorizer(stop_words='english')
#normalization
x_train_vect=vect.fit_transform(x_train)
x_test_vect=vect.transform(x_test)

x_train_vect

x_test_vect

#using a classifier
#supportvector machine (SVC)
#naive bayes theorem(multinomialNB)

from sklearn.svm import SVC
model=SVC()
model.fit(x_train_vect,y_train)

y_pred=model.predict(x_test_vect)

y_pred

y_test

